{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba0d0a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.17.2-py3-none-any.whl (9.9 MB)\n",
      "     ---------------------------------------- 9.9/9.9 MB 4.7 MB/s eta 0:00:00\n",
      "Collecting typing_extensions>=4.9.0\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\kausiki\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.24.0-py3-none-any.whl (460 kB)\n",
      "     -------------------------------------- 460.2/460.2 kB 4.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\kausiki\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\kausiki\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Collecting exceptiongroup\n",
      "  Downloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\kausiki\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting sniffio>=1.3.0\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\kausiki\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\kausiki\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\kausiki\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kausiki\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: typing_extensions, sniffio, outcome, h11, exceptiongroup, wsproto, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Uninstalling sniffio-1.2.0:\n",
      "      Successfully uninstalled sniffio-1.2.0\n",
      "Successfully installed exceptiongroup-1.2.0 h11-0.14.0 outcome-1.3.0.post0 selenium-4.17.2 sniffio-1.3.0 trio-0.24.0 trio-websocket-0.11.1 typing_extensions-4.9.0 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6400c622",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2843628863.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Import selenium\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Import selenium\n",
    "Import pandas as pd\n",
    "From selenium import webdriver\n",
    "Import warnings\n",
    "Import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b6bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.shine.com/\")\n",
    "\n",
    "job_title_field = driver.find_element(\"id\", \"qsb-keyword-sugg\")\n",
    "location_field = driver.find_element(\"id\", \"qsb-location-sugg\")\n",
    "search_button = driver.find_element(\"class name\", \"search\")\n",
    "\n",
    "job_title_field.send_keys(\"Data Analyst\")\n",
    "location_field.send_keys(\"Bangalore\")\n",
    "\n",
    "search_button.click()\n",
    "\n",
    "page_source = driver.page_source\n",
    "\n",
    "job_listings = driver.find_elements(\"class name\", \"result-display\")\n",
    "\n",
    "job_titles = []\n",
    "job_locations = []\n",
    "company_names = []\n",
    "experience_required = []\n",
    "\n",
    "for job in job_listings[:10]:\n",
    "    title = job.find_element(\"class name\", \"job_title_anchor\").text.strip()\n",
    "    location = job.find_element(\"class name\", \"result-jobs-details\").text.strip()\n",
    "    company = job.find_element(\"class name\", \"joblist-comp-name\").text.strip()\n",
    "    experience = job.find_element(\"class name\", \"joblist-exp\").text.strip()\n",
    "\n",
    "    job_titles.append(title)\n",
    "    job_locations.append(location)\n",
    "    company_names.append(company)\n",
    "    experience_required.append(experience)\n",
    "\n",
    "data = {\n",
    "    \"Job Title\": job_titles,\n",
    "    \"Job Location\": job_locations,\n",
    "    \"Company Name\": company_names,\n",
    "    \"Experience Required\": experience_required,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome\n",
    "url = \"https://www.shine.com\"\n",
    "driver.get(url)\n",
    "search_job = driver.find_element_by_xpath(\"//input[@class=\"form-control']\")   \n",
    "search_job\n",
    "search_job.send_keys('Data Scientist')\n",
    "search_loc=driver.find_element_by_id('class=\"input-label')\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "search_btn= driver .find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn\n",
    "search_btn=driver.find_element_by_class_name('btn')\n",
    "search_btn.click()\n",
    "title_tag=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tag\n",
    "job1_titles=[]\n",
    "for i in title_tag:\n",
    "    if i.text is None:\n",
    "        job1_titles.append('Not')\n",
    "    else:\n",
    "        job1_titles.append(i.text)\n",
    "job1_titles[:10]\n",
    "company_tag=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tag\n",
    "locations1_list=[]\n",
    "for i in locations_tag:\n",
    "    locations1_list.append(i.text)\n",
    "locations1_list[:10]\n",
    "print(len(job1_titles[:10])),print(len(companies1_names[:10])),print(len(locations1_list[:10]))\n",
    "driver=webdriver.Chrome\n",
    "driver.get('https://www.shine.com/job-search/data-science-jobs-in-bangalore-jobs')\n",
    "urls=[]\n",
    "job_description=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "for url in urls[:10]:   \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        description=driver.find_element_by_xpath(\"//section[@class='job-desc']\").text\n",
    "        job_description.append(description)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        job_description.append(\"Not Available\")\n",
    "print(len(job_description))\n",
    "job1=pd.DataFrame({})\n",
    "job1['title']=job1_titles[:10]\n",
    "job1['company_name']=companies1_names[:10]\n",
    "job1['location']=locations1_list[:10]\n",
    "job1['job_desc']=job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062827f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "driver = webdriver.Chrome('path_to_chromedriver')\n",
    "driver.get('https://www.shine.com/')\n",
    "search_box = driver.find_element_by_id('id_q')\n",
    "search_box.send_keys('Data Scientist')\n",
    "search_button = driver.find_element_by_id('id_l')\n",
    "search_button.click()\n",
    "location_filter = driver.find_element_by_xpath(\"//label[contains(text(),'Delhi/NCR')]\")\n",
    "location_filter.click()\n",
    "salary_filter = driver.find_element_by_xpath(\"//label[contains(text(),'3-6')]\")\n",
    "salary_filter.click()\n",
    "job_titles = driver.find_elements_by_xpath(\"//a[@class='job_title']\")\n",
    "job_locations = driver.find_elements_by_xpath(\"//li[@class='w-30 mr-10 result-display-location']\")\n",
    "company_names = driver.find_elements_by_xpath(\"//a[@class='result-display-company']\")\n",
    "experience_required = driver.find_elements_by_xpath(\"//li[@class='w-30 result-display-exp']\")\n",
    "data = {'Job Title': [title.text for title in job_titles[:10]],\n",
    "  'Job Location': [location.text for location in job_locations[:10]],\n",
    "  'Company Name': [company.text for company in company_names[:10]],\n",
    "  'Experience Required': [experience.text for experience in experience_required[:10]]}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705cbcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome\n",
    "driver.get('https://www.flipkart.com/')\n",
    "search_box = driver.find_element(By.XPATH, \"//input[@title='Search for products, brands and more']\")\n",
    "search_box.send_keys('sunglasses')\n",
    "search_box.submit()\n",
    "sunglasses = driver.find_elements(By.XPATH, \"//div[@class='_2kHMtA']\")\n",
    "data = []\n",
    "for i in range(100):\n",
    "  brand = sunglasses[i].find_element(By.XPATH, \".//div[@class='_2WkVRV']\")\n",
    "  description = sunglasses[i].find_element(By.XPATH, \".//a[@class='IRpwTa']\")\n",
    "  price = sunglasses[i].find_element(By.XPATH, \".//div[@class='_30jeq3 _1_WHN1']\")  \n",
    "  data.append({\n",
    "  'Brand': brand.text,\n",
    "  'ProductDescription': description.text,\n",
    "  'Price': price.text\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c589e652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b36195",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome\n",
    "url=\"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "search_g= driver.find_element_by_xpath(\"//input[@type='text']\")\n",
    "search_g\n",
    "search_g.send_keys('sneakers')\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn\n",
    "search_btn=driver.find_element_by_class_name('L0Z3Pu')\n",
    "search_btn.click()\n",
    "B_name=[]\n",
    "Price=[]\n",
    "P_desc=[]\n",
    "\n",
    "for i in range(3):\n",
    "    b_name=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    p_desc=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    price =driver.find_elements_by_xpath(\"//div[@class='_25b18c']\")\n",
    " \n",
    "    for j  in b_name:\n",
    "    B_name.append(j.text)\n",
    "    B_name[:100]\n",
    "for k in p_desc:\n",
    "    P_desc.append(k.text)\n",
    "    P_desc[:100]\n",
    "for l in price:\n",
    "    Price.append(l.text)\n",
    "    Price[:100]\n",
    "\n",
    "print(len(B_name[:100])),print(len(Price[:100])),print(len(P_desc[:100]))\n",
    "sun_gl=pd.DataFrame({})\n",
    "sun_gl['Brand_name']=B_name[:100]\n",
    "sun_gl['P_price']=Price[:100]\n",
    "sun_gl['Pr_desc']=P_desc[:100]\n",
    "sun_gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a19d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome\n",
    "driver.get(url)\n",
    "search_g= driver.find_element_by_xpath(\"//input[@type='text']\")\n",
    "search_g\n",
    "search_g.send_keys('Laptop')\n",
    "search_btn=driver.find_element_by_xpath(\"//input[@id='nav-search-submit-button']\")\n",
    "search_btn\n",
    "search_btn=driver.find_element_by_xpath(\"//input[@id='nav-search-submit-button']\")\n",
    "search_btn.click()\n",
    "for i in range(3):\n",
    "    b_name=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    p_desc=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    price =driver.find_elements_by_xpath(\"//div[@class='_25b18c']\")\n",
    "    for j  in b_name:\n",
    "    Title.append(j.text)\n",
    "    Title[:100]\n",
    "for k in p_desc:\n",
    "    P_desc.append(k.text)\n",
    "    P_desc[:100]\n",
    "for l in price:\n",
    "    Price.append(l.text)\n",
    "    Price[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4dfbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.azquotes.com/\")\n",
    "top_quotes_button = driver.find_element(By.LINK_TEXT, \"Top Quotes\")\n",
    "top_quotes_button.click()\n",
    "quotes = driver.find_elements(By.CSS_SELECTOR, \".title a\")\n",
    "authors = driver.find_elements(By.CSS_SELECTOR, \".author a\")\n",
    "types = driver.find_elements(By.CSS_SELECTOR, \".kw-box a\")\n",
    "\n",
    "for quote, author, quote_type in zip(quotes, authors, types):\n",
    "print(\"Quote:\", quote.text)\n",
    "print(\"Author:\", author.text)\n",
    "print(\"Type of Quote:\", quote_type.text)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc450dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "driver = webdriver.Chrome('path_to_chromedriver')\n",
    "driver.get('https://www.jagranjosh.com/')\n",
    "gk_option = driver.find_element_by_link_text('GK')\n",
    "gk_option.click()\n",
    "pm_option = driver.find_element_by_link_text('List of all Prime Ministers of India')\n",
    "pm_option.click()\n",
    "data = []\n",
    "table = driver.find_element_by_xpath('//table[@class=\"table4\"]')\n",
    "rows = table.find_elements_by_tag_name('tr')\n",
    "for row in rows:\n",
    "  cols = row.find_elements_by_tag_name('td')\n",
    "  if len(cols) == 4:\n",
    "  name = cols[0].text\n",
    "  born_dead = cols[1].text\n",
    "  term_of_office = cols[2].text\n",
    "  remarks = cols[3].text\n",
    "  data.append([name, born_dead, term_of_office, remarks])\n",
    "df = pd.DataFrame(data, columns=['Name', 'Born-Dead', 'Term of Office', 'Remarks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5000e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome()  # Corrected line\n",
    "driver.get('https://www.motor1.com/')\n",
    "search_bar = driver.find_element_by_id('search-input')\n",
    "search_bar.send_keys('50 most expensive cars')\n",
    "search_bar.submit()\n",
    "link = driver.find_element_by_link_text('50 Most Expensive Cars in the World')\n",
    "link.click()\n",
    "car_names = driver.find_elements_by_xpath('//div[@class=\"article-content\"]/h3')\n",
    "car_prices = driver.find_elements_by_xpath('//div[@class=\"article-content\"]/p')\n",
    "data = []\n",
    "for name, price in zip(car_names, car_prices):\n",
    "    data.append([name.text, price.text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Car Name', 'Price'])\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
